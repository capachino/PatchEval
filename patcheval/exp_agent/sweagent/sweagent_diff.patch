diff -ruN SWE-agent_ori/config/default.yaml SWE-agent/config/default.yaml
--- SWE-agent_ori/config/default.yaml	2025-11-18 21:41:43.333549332 +0800
+++ SWE-agent/config/default.yaml	2025-11-18 18:27:44.677721754 +0800
@@ -42,6 +42,7 @@
       - path: tools/registry
       - path: tools/edit_anthropic
       - path: tools/review_on_submit_m
+      - path: tools/check_fix
     registry_variables:
       USE_FILEMAP: 'true'
       SUBMIT_REVIEW_MESSAGES:
diff -ruN SWE-agent_ori/.gitignore SWE-agent/.gitignore
--- SWE-agent_ori/.gitignore	2025-11-18 21:41:43.322549080 +0800
+++ SWE-agent/.gitignore	2025-11-18 18:27:44.666721501 +0800
@@ -207,4 +207,6 @@
 # SWE-smith
 agent_conf
 sb-cli-reports/
-trajectories_sft/
\ No newline at end of file
+trajectories_sft/
+
+trajectories/
\ No newline at end of file
diff -ruN SWE-agent_ori/sweagent/agent/models.py SWE-agent/sweagent/agent/models.py
--- SWE-agent_ori/sweagent/agent/models.py	2025-11-18 21:43:39.787224148 +0800
+++ SWE-agent/sweagent/agent/models.py	2025-11-18 21:59:03.625618223 +0800
@@ -1,3 +1,6 @@
+# Copyright (c) 2025 SWE-agent
+# Copyright (c) 2025 [ByteDance Ltd. and/or its affiliates.]
+# SPDX-License-Identifier: MIT
 from __future__ import annotations
 
 import copy
@@ -710,6 +713,9 @@
         if self.lm_provider == "anthropic":
             completion_kwargs["max_tokens"] = self.model_max_output_tokens
         try:
+            litellm.drop_params = True
+            if "gpt-5" in self.config.name:
+                temperature = 1
             response: litellm.types.utils.ModelResponse = litellm.completion(  # type: ignore
                 model=self.config.name,
                 messages=messages,
diff -ruN SWE-agent_ori/sweagent/environment/swe_env.py SWE-agent/sweagent/environment/swe_env.py
--- SWE-agent_ori/sweagent/environment/swe_env.py	2025-11-18 21:41:43.366550090 +0800
+++ SWE-agent/sweagent/environment/swe_env.py	2025-11-18 21:59:32.522297831 +0800
@@ -1,3 +1,6 @@
+# Copyright (c) 2025 SWE-agent
+# Copyright (c) 2025 [ByteDance Ltd. and/or its affiliates.]
+# SPDX-License-Identifier: MIT
 import asyncio
 import logging
 import shlex
@@ -55,7 +58,7 @@
         deployment: AbstractDeployment,
         repo: Repo | RepoConfig | None,
         post_startup_commands: list[str],
-        post_startup_command_timeout: int = 500,
+        post_startup_command_timeout: int = 2000,
         hooks: list[EnvHook] | None = None,
         name: str = "main",
     ):
@@ -109,9 +112,17 @@
     def start(self) -> None:
         """Start the environment and reset it to a clean state."""
         self._init_deployment()
-        self.reset()
-        for command in self._post_startup_commands:
+        # self.reset()
+        repo = self.repo.repo_name.split("/")[-1]
+        self.communicate(f"cd /{self.repo.repo_name} && export ROOT=$(pwd -P) && export PROJECTAME={repo}", check="raise", timeout=self.post_startup_command_timeout)
+        for command in self._post_startup_commands :
             self.communicate(command, check="raise", timeout=self.post_startup_command_timeout)
+        
+        self.communicate('git config --global user.email "test@example.com"', check="warn", timeout=self.post_startup_command_timeout)
+        self.communicate('git config --global user.name "test"', check="warn", timeout=self.post_startup_command_timeout)
+        self.communicate('git rm -r --cached .', check="warn", timeout=self.post_startup_command_timeout)
+        self.communicate('git add .', check="warn", timeout=self.post_startup_command_timeout)
+        self.communicate('git commit --no-verify -m "init"', check="warn", timeout=self.post_startup_command_timeout)
 
     def _copy_repo(self) -> None:
         """Clone/copy repository/codebase in container"""
@@ -143,7 +154,7 @@
         """
         self.communicate(input="cd /", check="raise")
         self._copy_repo()
-        self._reset_repository()
+        # self._reset_repository()
         self._chook.on_environment_startup()
 
     def _reset_repository(self) -> None:
diff -ruN SWE-agent_ori/sweagent/__init__.py SWE-agent/sweagent/__init__.py
--- SWE-agent_ori/sweagent/__init__.py	2025-11-18 21:41:43.364550045 +0800
+++ SWE-agent/sweagent/__init__.py	2025-11-18 18:27:44.701722305 +0800
@@ -44,6 +44,13 @@
 assert TOOLS_DIR.is_dir(), TOOLS_DIR
 
 TRAJECTORY_DIR = Path(os.getenv("SWE_AGENT_TRAJECTORY_DIR", PACKAGE_DIR.parent / "trajectories"))
+
+
+print(PACKAGE_DIR)
+print(PACKAGE_DIR.parent)
+
+
+
 assert TRAJECTORY_DIR.is_dir(), TRAJECTORY_DIR
 
 
diff -ruN SWE-agent_ori/sweagent/run/run.py SWE-agent/sweagent/run/run.py
--- SWE-agent_ori/sweagent/run/run.py	2025-11-18 21:41:43.371550205 +0800
+++ SWE-agent/sweagent/run/run.py	2025-11-18 18:27:44.706722419 +0800
@@ -1,3 +1,6 @@
+# Copyright (c) 2025 SWE-agent
+# Copyright (c) 2025 [ByteDance Ltd. and/or its affiliates.]
+# SPDX-License-Identifier: MIT
 """[cyan][bold]Main command line interface for SWE-agent.[/bold][/cyan]
 
 [cyan][bold]=== USAGE ===[/bold][/cyan]
@@ -32,7 +35,193 @@
 import sys
 
 import rich
+import litellm
 
+litellm.register_model({
+        "openai/doubao-seed-1-6-251015": {
+        "max_tokens": 8192,
+        "max_input_tokens": 128000,
+        "max_output_tokens": 8192,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    }
+})
+
+litellm.register_model({
+        "openai/deepseek-v3-250324": {
+        "max_tokens": 8192,
+        "max_input_tokens": 128000,
+        "max_output_tokens": 8192,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    }
+})
+litellm.register_model({
+        "openai/deepseek-r1-250528": {
+        "max_tokens": 8192,
+        "max_input_tokens": 128000,
+        "max_output_tokens": 8192,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    }
+})
+litellm.register_model({
+        "openai/doubao-seed-1-6-250615": {
+        "max_tokens": 8192,
+        "max_input_tokens": 128000,
+        "max_output_tokens": 8192,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    }
+})
+litellm.register_model({
+        "openai/doubao-seed-1-6-thinking-250615": {
+        "max_tokens": 8192,
+        "max_input_tokens": 128000,
+        "max_output_tokens": 8192,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    }
+})
+litellm.register_model({
+        "azure/gemini-2.5-pro": {
+        "max_tokens": 65535,
+        "max_input_tokens": 1048576,
+        "max_output_tokens": 65535,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/claude-3-7-sonnet-20250219": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/claude-sonnet-4-20250514": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/gpt-4.1-2025-04-14": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/qwen3-coder-480b-a35b-instruct": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "openai/kimi-k2-250711": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "openai/deepseek-v3-0324": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "openai",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/gpt-5-2025-08-07": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": True,
+        "supports_tool_choice": True
+    },
+})
+litellm.register_model({
+        "azure/o3-2025-04-16": {
+        "max_tokens": 128000,
+        "max_input_tokens": 200000,
+        "max_output_tokens": 128000,
+        "input_cost_per_token": 0,
+        "output_cost_per_token": 0,
+        "litellm_provider": "azure",
+        "mode": "chat",
+        "supports_function_calling": False,
+        "supports_tool_choice": False
+    },
+})
+
+myparser = argparse.ArgumentParser()
 
 def get_cli():
     parser = argparse.ArgumentParser(add_help=False)
@@ -144,4 +333,5 @@
 
 
 if __name__ == "__main__":
+    
     sys.exit(main())
diff -ruN SWE-agent_ori/sweagent/run/run_single.py SWE-agent/sweagent/run/run_single.py
--- SWE-agent_ori/sweagent/run/run_single.py	2025-11-18 21:41:43.371550205 +0800
+++ SWE-agent/sweagent/run/run_single.py	2025-11-18 22:00:06.057086521 +0800
@@ -1,3 +1,6 @@
+# Copyright (c) 2025 SWE-agent
+# Copyright (c) 2025 [ByteDance Ltd. and/or its affiliates.]
+# SPDX-License-Identifier: MIT
 """[cyan][bold]Run SWE-agent on a single instance taken from github or similar.[/bold][/cyan]
 
 [cyan][bold]=== BASIC OPTIONS ===[/bold][/cyan]
@@ -162,8 +165,9 @@
         return self._chooks.hooks
 
     @classmethod
-    def from_config(cls, config: RunSingleConfig) -> Self:
+    def from_config(cls, config: RunSingleConfig, output_dir) -> Self:
         load_environment_variables(config.env_var_path)
+        config.output_dir = Path(output_dir)
         config.set_default_output_dir()
         config.output_dir.mkdir(parents=True, exist_ok=True)
         agent = get_agent_from_config(config.agent)
@@ -207,18 +211,22 @@
         self.env.close()
 
 
-def run_from_config(config: RunSingleConfig):
-    RunSingle.from_config(config).run()
+def run_from_config(config: RunSingleConfig, output_dir):
+    RunSingle.from_config(config, output_dir).run()
 
 
 def run_from_cli(args: list[str] | None = None):
     if args is None:
         args = sys.argv[1:]
+    if "--output_dir" in args:
+        idx = args.index("--output_dir")
+        output_dir= args[idx + 1]
+        args = args[:idx] + args[idx+2:]
     assert __doc__ is not None
     help_text = (  # type: ignore
         __doc__ + "\n[cyan][bold]=== ALL THE OPTIONS ===[/bold][/cyan]\n\n" + ConfigHelper().get_help(RunSingleConfig)
     )
-    run_from_config(BasicCLI(RunSingleConfig, help_text=help_text).get_config(args))  # type: ignore
+    run_from_config(BasicCLI(RunSingleConfig, help_text=help_text).get_config(args), output_dir)  # type: ignore
 
 
 if __name__ == "__main__":
diff -ruN SWE-agent_ori/sweagent/tools/tools.py SWE-agent/sweagent/tools/tools.py
--- SWE-agent_ori/sweagent/tools/tools.py	2025-11-18 21:41:43.372550228 +0800
+++ SWE-agent/sweagent/tools/tools.py	2025-11-18 22:00:25.799550835 +0800
@@ -1,3 +1,6 @@
+# Copyright (c) 2025 SWE-agent
+# Copyright (c) 2025 [ByteDance Ltd. and/or its affiliates.]
+# SPDX-License-Identifier: MIT
 """
 This module contains the configuration for the tools that are made available to the agent.
 
@@ -136,10 +139,10 @@
     Unlike `install_commands`, these commands are part of the environment state.
     """
 
-    execution_timeout: int = 30
+    execution_timeout: int = 1000
     """Timeout for executing commands in the environment"""
 
-    install_timeout: int = 300
+    install_timeout: int = 1000
     """Timeout used for each of the installation commands"""
 
     total_execution_timeout: int = 1800
diff -ruN SWE-agent_ori/tools/check_fix/bin/chek_vulnerability SWE-agent/tools/check_fix/bin/chek_vulnerability
--- SWE-agent_ori/tools/check_fix/bin/chek_vulnerability	1970-01-01 08:00:00.000000000 +0800
+++ SWE-agent/tools/check_fix/bin/chek_vulnerability	2025-11-18 18:27:44.782724163 +0800
@@ -0,0 +1,10 @@
+#!/bin/bash
+
+
+cp /tmp/secret/test.patch /workspace/test.patch
+cp -r /workspace/${PROJECTAME} /tmp/${PROJECTAME}
+bash /workspace/vul-run.sh
+[ -d "/workspace/${PROJECTAME}" ] && rm -rf /workspace/${PROJECTAME}/* 
+cp -r /tmp/${PROJECTAME}/* /workspace/${PROJECTAME}/  
+[ -d "/tmp/${PROJECTAME}" ] && rm -rf /tmp/${PROJECTAME}
+rm /workspace/test.patch
\ No newline at end of file
diff -ruN SWE-agent_ori/tools/check_fix/config.yaml SWE-agent/tools/check_fix/config.yaml
--- SWE-agent_ori/tools/check_fix/config.yaml	1970-01-01 08:00:00.000000000 +0800
+++ SWE-agent/tools/check_fix/config.yaml	2025-11-18 18:27:44.782724163 +0800
@@ -0,0 +1,5 @@
+tools:
+  chek_vulnerability:
+    signature: "chek_vulnerability"
+    docstring: "Automatically run a PoC program and output the status of the current vulnerability."
+    arguments: []
\ No newline at end of file
diff -ruN SWE-agent_ori/tools/check_vulnerability/bin/chek_vulnerability SWE-agent/tools/check_vulnerability/bin/chek_vulnerability
--- SWE-agent_ori/tools/check_vulnerability/bin/chek_vulnerability	1970-01-01 08:00:00.000000000 +0800
+++ SWE-agent/tools/check_vulnerability/bin/chek_vulnerability	2025-11-18 18:27:44.783724186 +0800
@@ -0,0 +1,7 @@
+#!/bin/bash
+
+cp -r /workspace/${PROJECTAME} /tmp/${PROJECTAME}
+bash /workspace/vul-run.sh
+[ -d "/workspace/${PROJECTAME}" ] && rm -rf /workspace/${PROJECTAME}/* 
+cp -r /tmp/${PROJECTAME}/* /workspace/${PROJECTAME}/  
+[ -d "/tmp/${PROJECTAME}" ] && rm -rf /tmp/${PROJECTAME}
diff -ruN SWE-agent_ori/tools/check_vulnerability/config.yaml SWE-agent/tools/check_vulnerability/config.yaml
--- SWE-agent_ori/tools/check_vulnerability/config.yaml	1970-01-01 08:00:00.000000000 +0800
+++ SWE-agent/tools/check_vulnerability/config.yaml	2025-11-18 18:27:44.783724186 +0800
@@ -0,0 +1,5 @@
+tools:
+  chek_vulnerability:
+    signature: "chek_vulnerability"
+    docstring: "Automatically run a PoC program and output the status of the current vulnerability."
+    arguments: []
\ No newline at end of file
